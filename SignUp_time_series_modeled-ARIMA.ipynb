{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import dataiku\n",
    "import pandas as pd, numpy as np\n",
    "from dataiku import pandasutils as pdu\n",
    "\n",
    "# Read recipe inputs\n",
    "dna_CC11_PD_grp_prepared = dataiku.Dataset(\"DNA_CC11_PD_grp_prepared\")\n",
    "dna_CC11_PD_grp_prepared_df = dna_CC11_PD_grp_prepared.get_dataframe()\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('Solarize_Light2')\n",
    "\n",
    "#df = pd.DataFrame(dna_CC11_PD_grp_prepared_df, columns=['date','ID_count'])\n",
    "df = pd.DataFrame(dna_CC11_PD_grp_prepared_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns\n",
    "#df.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "days = pd.date_range('2011-01-01', periods=111, freq='M')\n",
    "\n",
    "df_new=pd.DataFrame()\n",
    "\n",
    "df_new['Date_2'] = pd.to_datetime(days)\n",
    "df_new['val']=0\n",
    "df_new['year_j']=pd.DatetimeIndex(df_new['Date_2']).year\n",
    "df_new['month_j']=pd.DatetimeIndex(df_new['Date_2']).month\n",
    "#df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new.info()\n",
    "#df_new.Date_2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin= pd.merge(df_new, df, how='left',left_on=['year_j','month_j'], right_on=['Sign up year', 'Sign up Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin=df_fin.fillna(0)\n",
    "df_fin['data']=df_fin['val']+df_fin['ID_count']\n",
    "df_fin=df_fin[['Date_2','data']]\n",
    "#df_fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_fin.copy()\n",
    "df.columns=['time','data']\n",
    "df = df.set_index(['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.asfreq('M')\n",
    "#df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:-10, :]\n",
    "test = df.iloc[-10:, :]\n",
    "pred = test.copy()\n",
    "df.plot(figsize=(12,3))\n",
    "print(\"      Monthwise SignRate for C11 for Course Category Personal Development\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['z_data'] = (df['data'] - df.data.rolling(window=12).mean()) / df.data.rolling(window=12).std()\n",
    "df['zp_data'] = df['z_data'] - df['z_data'].shift(12)\n",
    "\n",
    "fig, ax = plt.subplots(3,figsize=(12, 9))\n",
    "ax[0].plot(df.index, df.data, label='raw data')\n",
    "ax[0].plot(df.data.rolling(window=12).mean(), label=\"rolling mean\");\n",
    "ax[0].plot(df.data.rolling(window=12).std(), label=\"rolling std (x10)\");\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"Analyzing the Sign-up Rate for trend and lags\");\n",
    "\n",
    "ax[1].plot(df.index, df.z_data, label=\"de-trended data\")\n",
    "ax[1].plot(df.z_data.rolling(window=12).mean(), label=\"rolling mean\");\n",
    "ax[1].plot(df.z_data.rolling(window=12).std(), label=\"rolling std (x10)\");\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"Analyzing the detrended Sign-up Rate for lags\");\n",
    "\n",
    "ax[2].plot(df.index, df.zp_data, label=\"12 lag differenced de-trended data\")\n",
    "ax[2].plot(df.zp_data.rolling(window=12).mean(), label=\"rolling mean\");\n",
    "ax[2].plot(df.zp_data.rolling(window=12).std(), label=\"rolling std (x10)\");\n",
    "ax[2].legend()\n",
    "ax[2].set_title(\"Analyzing the lagged SignRate trend for Stationarity\")\n",
    "plt.tight_layout()\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "print(\" > Is the data stationary ?\")\n",
    "dftest = adfuller(df.data, autolag='AIC')\n",
    "print(\"Test statistic = {:.3f}\".format(dftest[0]))\n",
    "print(\"P-value = {:.3f}\".format(dftest[1]))\n",
    "print(\"Critical values :\")\n",
    "for k, v in dftest[4].items():\n",
    "    print(\"\\t{}: {} - The data is {} stationary with {}% confidence\".format(k, v, \"not\" if v<dftest[0] else \"\", 100-int(k[:-1])))\n",
    "\n",
    "print(\"\\n > Is the de-trended data stationary ?\")\n",
    "dftest = adfuller(df.z_data.dropna(), autolag='AIC')\n",
    "print(\"Test statistic = {:.3f}\".format(dftest[0]))\n",
    "print(\"P-value = {:.3f}\".format(dftest[1]))\n",
    "print(\"Critical values :\")\n",
    "for k, v in dftest[4].items():\n",
    "    print(\"\\t{}: {} - The data is {} stationary with {}% confidence\".format(k, v, \"not\" if v<dftest[0] else \"\", 100-int(k[:-1])))\n",
    "\n",
    "print(\"\\n > Is the 12-lag differenced de-trended data stationary ?\")\n",
    "dftest = adfuller(df.zp_data.dropna(), autolag='AIC')\n",
    "print(\"Test statistic = {:.3f}\".format(dftest[0]))\n",
    "print(\"P-value = {:.3f}\".format(dftest[1]))\n",
    "print(\"Critical values :\")\n",
    "for k, v in dftest[4].items():\n",
    "    print(\"\\t{}: {} - The data is {} stationary with {}% confidence\".format(k, v, \"not\" if v<dftest[0] else \"\", 100-int(k[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(12,6))\n",
    "ax[0] = plot_acf(df.z_data.dropna(), ax=ax[0], lags=20)\n",
    "ax[1] = plot_pacf(df.z_data.dropna(), ax=ax[1], lags=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_fin.copy()\n",
    "df.columns=['time','data']\n",
    "df = df.set_index(['time'])\n",
    "df=df.asfreq('M')\n",
    "train = df.iloc[:-10, :]\n",
    "test = df.iloc[-10:, :]\n",
    "pred = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.index = pd.to_datetime(train.index)\n",
    "test.index = pd.to_datetime(test.index)\n",
    "pred = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Data Information')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Data Information')\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, Holt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('Solarize_Light2')\n",
    "\n",
    "\n",
    "model = SimpleExpSmoothing(np.asarray(train['data']))\n",
    "model._index = pd.to_datetime(train.index)\n",
    "\n",
    "fit1 = model.fit()\n",
    "pred1 = fit1.forecast(10)\n",
    "fit2 = model.fit(smoothing_level=.2)\n",
    "pred2 = fit2.forecast(10)\n",
    "fit3 = model.fit(smoothing_level=.5)\n",
    "pred3 = fit3.forecast(10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(train.index[50:], train.values[50:])\n",
    "ax.plot(test.index, test.values, color=\"gray\")\n",
    "for p, f, c in zip((pred1, pred2, pred3),(fit1, fit2, fit3),('#ff7823','#3c763d','c')):\n",
    "    ax.plot(train.index[50:], f.fittedvalues[50:], color=c)\n",
    "    ax.plot(test.index, p, label=\"alpha=\"+str(f.params['smoothing_level'])[:3], color=c)\n",
    "plt.title(\"Simple Exponential Smoothing\")\n",
    "plt.legend();\n",
    "\n",
    "model = Holt(np.asarray(train['data']))\n",
    "model._index = pd.to_datetime(train.index)\n",
    "\n",
    "fit1 = model.fit(smoothing_level=.3, smoothing_slope=.05)\n",
    "pred1 = fit1.forecast(10)\n",
    "fit2 = model.fit(optimized=True)\n",
    "pred2 = fit2.forecast(10)\n",
    "fit3 = model.fit(smoothing_level=.3, smoothing_slope=.2)\n",
    "pred3 = fit3.forecast(10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(train.index[50:], train.values[50:])\n",
    "ax.plot(test.index, test.values, color=\"gray\")\n",
    "for p, f, c in zip((pred1, pred2, pred3),(fit1, fit2, fit3),('#ff7823','#3c763d','c')):\n",
    "    ax.plot(train.index[50:], f.fittedvalues[50:], color=c)\n",
    "    ax.plot(test.index, p, label=\"alpha=\"+str(f.params['smoothing_level'])[:4]+\", beta=\"+str(f.params['smoothing_slope'])[:4], color=c)\n",
    "plt.title(\"Holt's Exponential Smoothing\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomposition = seasonal_decompose(df['data'])\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(df['data'], label='Original')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residuals')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import numpy as np\n",
    "\n",
    "model = ExponentialSmoothing(np.asarray(train['data']), trend='add', seasonal=None)\n",
    "model2 = ExponentialSmoothing(np.asarray(train['data']), trend='add', seasonal=None, damped=True)\n",
    "model._index = pd.to_datetime(train.index)\n",
    "\n",
    "fit1 = model.fit()\n",
    "fit2 = model2.fit()\n",
    "pred1 = fit1.forecast(10)\n",
    "pred2 = fit2.forecast(10)\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(12, 12))\n",
    "ax[0].plot(train.index[50:], train.values[50:])\n",
    "ax[0].plot(test.index, test.values, color=\"gray\", label=\"truth\")\n",
    "ax[1].plot(train.index[50:], train.values[50:])\n",
    "ax[1].plot(test.index, test.values, color=\"gray\", label=\"truth\")\n",
    "for p, f, c in zip((pred1, pred2),(fit1, fit2),('#ff7823','#3c763d')):\n",
    "    ax[0].plot(train.index[50:], f.fittedvalues[50:], color=c)\n",
    "    ax[1].plot(train.index[50:], f.fittedvalues[50:], color=c)\n",
    "    ax[0].plot(test.index, p, label=\"alpha=\"+str(f.params['smoothing_level'])[:4]+\", beta=\"+str(f.params['smoothing_slope'])[:4]+ \", damping=\"+str(True if f.params['damping_slope']>0 else False), color=c)\n",
    "    ax[1].plot(test.index, p, label=\"alpha=\"+str(f.params['smoothing_level'])[:4]+\", beta=\"+str(f.params['smoothing_slope'])[:4]+ \", damping=\"+str(True if f.params['damping_slope']>0 else False), color=c)\n",
    "ax[0].set_title(\"Damped Exponential Smoothing\");\n",
    "ax[1].set_title(\"Damped Exponential Smoothing - zoomed\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, sharex=True, figsize=(12,6))\n",
    "ax[0].plot(df.data.values);\n",
    "ax[0].set_title(\"Raw data\");\n",
    "ax[1].plot(np.log(df.data.values));\n",
    "ax[1].set_title(\"Logged data (deflated)\");\n",
    "ax[1].set_ylim(0, 15);\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12,6))\n",
    "first_diff = (np.log(df.data)- np.log(df.data).shift()).dropna()\n",
    "ax[0, 0] = plot_acf(np.log(df.data), ax=ax[0, 0], lags=20, title=\"ACF - Logged data\")\n",
    "ax[1, 0] = plot_pacf(np.log(df.data), ax=ax[1, 0], lags=20, title=\"PACF - Logged data\")\n",
    "ax[0, 1] = plot_acf(first_diff , ax=ax[0, 1], lags=20, title=\"ACF - Differenced Logged data\")\n",
    "ax[1, 1] = plot_pacf(first_diff, ax=ax[1, 1], lags=20, title=\"PACF - Differenced Logged data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import kpss\n",
    "\n",
    "print(\" > Is the data stationary ?\")\n",
    "dftest = kpss(np.log(df.data), 'ct')\n",
    "print(\"Test statistic = {:.3f}\".format(dftest[0]))\n",
    "print(\"P-value = {:.3f}\".format(dftest[1]))\n",
    "print(\"Critical values :\")\n",
    "for k, v in dftest[3].items():\n",
    "    print(\"\\t{}: {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "model = ARIMA(df.data.dropna(), (1, 0, 1))\n",
    "res_000 = model.fit()\n",
    "print(res_000.summary())\n",
    "\n",
    "model = ARIMA(df.data.dropna(), (1, 0, 0))\n",
    "res_010 = model.fit()\n",
    "print(res_010.summary())\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharey=True, figsize=(12, 6))\n",
    "ax[0].plot(res_000.resid.values, alpha=0.7, label='variance={:.3f}'.format(np.std(res_000.resid.values)));\n",
    "ax[0].hlines(0, xmin=0, xmax=350, color='r');\n",
    "ax[0].set_title(\"ARIMA(1,0,1)\");\n",
    "ax[0].legend();\n",
    "ax[1].plot(res_010.resid.values, alpha=0.7, label='variance={:.3f}'.format(np.std(res_010.resid.values)));\n",
    "ax[1].hlines(0, xmin=0, xmax=350, color='r');\n",
    "ax[1].set_title(\"ARIMA(1,0,0)\");\n",
    "ax[1].legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ARIMA(train.data.dropna(), (1, 0, 1))\n",
    "res_101 = model.fit()\n",
    "pred_ARIMA = res_101.forecast(10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "df.index = pd.to_datetime(df.index, format=\"%Y-%m\")\n",
    "df.data.dropna()[50:].plot(ax=ax);\n",
    "ax.vlines('2019-06', 13, 14.5, linestyle='--', color='r', label='Start of forecast');\n",
    "\n",
    "# - NOTE from the official documentation :\n",
    "# -- The dynamic keyword affects in-sample prediction.\n",
    "# -- If dynamic is False, then the in-sample lagged values are used for prediction.\n",
    "# -- If dynamic is True, then in-sample forecasts are used in place of lagged dependent variables.\n",
    "ax = res_101.plot_predict('2019-06', '2020-12', dynamic=True, plot_insample=False, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ARIMA = res_101.predict(start='2019-06-30', end='2020-03-31')\n",
    "#pred_ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#MAPE\n",
    "y_true=test.data.values\n",
    "y_pred=pred_ARIMA.values\n",
    "\n",
    "forecast_error = y_true-y_pred\n",
    "\n",
    "mean_forecast_error = np.mean(forecast_error)\n",
    "mean_absolute_error = np.mean( np.abs(forecast_error) )\n",
    "mean_squared_error = np.mean(forecast_error**2)\n",
    "rmse = math.sqrt(mean_squared_error)\n",
    "MAPE=np.mean(np.abs((y_true-y_pred)/y_true))*100\n",
    "print('mean_forecast_error= %f'%mean_forecast_error)\n",
    "print('mean_absolute_error= %f'%mean_absolute_error)\n",
    "print('mean_squared_error= %f'%mean_squared_error)\n",
    "print('rmse= %f'%rmse)\n",
    "print('MAPE= %f'%MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_modeled=df.copy()\n",
    "time_series_modeled['pred']= res_101.predict(start='2011-01-31', end='2020-03-31').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Signup Rate prediction Values for C11 and Personal Development')\n",
    "time_series_modeled.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_df = model # For this sample code, simply copy input to output\n",
    "time_series_modeled_df=time_series_modeled\n",
    "\n",
    "# Write recipe outputs\n",
    "\n",
    "time_series_modeled = dataiku.Dataset(\"time_series_modeled\")\n",
    "time_series_modeled.write_with_schema(time_series_modeled_df)"
   ]
  }
 ],
 "metadata": {
  "associatedRecipe": "compute_time_series_modeled",
  "creator": "admin",
  "customFields": {},
  "kernelspec": {
   "display_name": "Python (env Python3)",
   "language": "python",
   "name": "py-dku-venv-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "tags": [
   "recipe-editor"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
